{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n",
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n",
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: seezo-chatbot\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phoenix.otel.otel.TracerProvider at 0x1602ecf50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import phoenix as px\n",
    "from phoenix.otel import register\n",
    "\n",
    "project_name=\"seezo-chatbot\"\n",
    "\n",
    "session = px.launch_app()\n",
    "register(project_name= project_name) #project_name=\"my-llm-app\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db_NEW\")\n",
    "collection = client.get_collection(name=\"seezo_website\")\n",
    "results = collection.get(include=[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How can I \\nstill try Seezo?', 'Check out Seezo!', 'Seezo.io is a platform designed to enhance application security by providing automated security design \\nreviews for every feature developed by a company.', 'Seezo is highly recommended.', 'Seezo uses a combination \\nof Multi-modal RAG (scans images, tables, flowcharts, and text), prompt engineering ( to look for relevant \\nsecurity controls), and decision trees (to reduce hallucination) to achieve these results.', 'Seezo can help solve this.', 'Seezo.io is a platform dedicated to offering automated security design reviews for software features.', 'With context-specific security insights, Seezo.io ensures that security considerations are \\nintegrated from the start, helping you build a resilient application right from the design phase.', 'However, Seezo offers significant advantages:\\nConsistent output: Seezo automatically asks the right questions, providing \\nconsistent outputs regardless of the Security Engineer‚Äôs level of knowledge.', 'Seezo is designed with enterprise needs in mind and supports multiple \\ndeployment options to comply with your internal standards.']\n"
     ]
    }
   ],
   "source": [
    "def retrieve_context_chromadb(query, collection, top_k=10):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    return results['documents'][0]\n",
    "\n",
    "query = \"What is seezo?\"\n",
    "context = retrieve_context_chromadb(query, collection)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seezo ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not (groq_api_key := os.getenv(\"GROQ_API_KEY\")):\n",
    "    groq_api_key = getpass(\"üîë Enter your Groq API key: \")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.groq import GroqInstrumentor\n",
    "\n",
    "GroqInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b1d0465cfb4571beec5e9749ef04e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='You:', layout=Layout(width='80%'), placeholder='Type your message here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9790864bf74a25a147d8cf600d3e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Send', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4eda8e50bf4527bfd1d211f9a0a5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from groq import Groq\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "# embedding function\n",
    "embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Groq client\n",
    "groq_client = Groq()\n",
    "\n",
    "# trace CSV file path\n",
    "file_path_csv = \"./new_csv.csv\"\n",
    "\n",
    "# interactive widgets\n",
    "input_box = widgets.Text(\n",
    "    placeholder=\"Type your message here...\",\n",
    "    description=\"You:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "send_button = widgets.Button(description=\"Send\", button_style='primary')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "\n",
    "conversation_history = []\n",
    "\n",
    "def chat_interact(_):\n",
    "    user_query = input_box.value.strip()\n",
    "    if not user_query:\n",
    "        return  # Ignore empty submissions\n",
    "\n",
    "    input_box.value = \"\"\n",
    "    \n",
    "    # Exit condition\n",
    "    if user_query.lower() in [\"exit\", \"quit\"]:\n",
    "        with output_area:\n",
    "            display(Markdown(\"**Bot:** Goodbye! üòä\"))\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Retrieve context from ChromaDB\n",
    "        query_embedding = embedding_fn([user_query])\n",
    "        results = collection.query(\n",
    "            query_embeddings=query_embedding,\n",
    "            n_results=50,\n",
    "            include=[\"documents\"]\n",
    "        )\n",
    "        retrieved_context = \" \".join(results.get(\"documents\", [[]])[0])[:8192]  # Context length limit\n",
    "\n",
    "        # Build messages with conversation history\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": f\"Answer based on context: {retrieved_context}\"},\n",
    "        ] + conversation_history + [\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ]\n",
    "\n",
    "        # Generate response\n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            messages=messages,\n",
    "            temperature=0.1,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        bot_response = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Update conversation history\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "\n",
    "        # Display conversation\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            for message in conversation_history:\n",
    "                display(Markdown(f\"**{message['role'].capitalize()}:** {message['content']}\"))\n",
             time.sleep(2)
    "\n",
    "        # Update CSV file with new interaction data\n",
    "        df = px.Client().get_spans_dataframe(project_name=project_name).tail(1)\n",
    "        \n",
    "        # Check if file exists and append\n",
    "        if os.path.exists(file_path_csv):\n",
    "            existing_df = pd.read_csv(file_path_csv)\n",
    "            combined_df = pd.concat([existing_df, df])\n",
    "        else:\n",
    "            combined_df = df\n",
    "\n",
    "        # Save back to CSV\n",
    "        combined_df.to_csv(file_path_csv, index=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        with output_area:\n",
    "            display(Markdown(f\"**Error:** {str(e)}\"))\n",
    "\n",
    "# Bind button click event\n",
    "send_button.on_click(chat_interact)\n",
    "\n",
    "# Display widgets\n",
    "display(input_box, send_button, output_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'hey I want to know about seezo'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Seezo is a platform designed to enhance application security by providing automated security design reviews for every feature developed by a company. It uses a combination of Multi-modal RAG (scans images, tables, flowcharts, and text), prompt engineering (to look for relevant security controls), and decision trees (to reduce hallucination) to achieve this.\\n\\nHere are some key benefits of using Seezo:\\n\\n1. **Consistent output**: Seezo automatically asks the right questions, providing consistent outputs regardless of the Security Engineer‚Äôs level of knowledge.\\n2. **Customizable**: Seezo integrates with your coding standards, understands company-specific jargon, and tailors rules to match your risk profile.\\n3. **Seamless workflow integration**: Seezo integrates with your developer workflow, eliminating the need to transfer data between systems.\\n4. **Context-specific security insights**: Seezo provides security requirements to developers before they start coding, helping to build a resilient application from the design phase.\\n5. **Scalability**: Seezo helps security teams scale design reviews while empowering them to focus on other complex challenges.\\n\\nSeezo is designed with enterprise needs in mind and supports multiple deployment options to comply with your internal standards. If you're interested in learning more, you can book a demo or sign up for a free trial to see how Seezo can help your organization improve its application security.\"}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = px.Client().get_spans_dataframe(project_name= project_name)\n",
    "\n",
    "\n",
    "file_path_csv = \"./new_csv.csv\"\n",
    "\n",
    "if os.path.exists(file_path_csv):\n",
    "    existing_df = pd.read_csv(file_path_csv)\n",
    "    combined_df = pd.concat([existing_df, df])\n",
    "else:\n",
    "    combined_df = df\n",
    "\n",
    "combined_df.to_csv(file_path_csv, index=False)\n",
    "\n",
    "# df.to_json('new_json.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    QAEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    run_evals,\n",
    ")\n",
    "from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n",
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df = get_qa_with_reference(px.active_session(),project_name=project_name)\n",
    "retrieved_documents_df = get_retrieved_documents(px.active_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = \"\"\n",
    "\n",
    "eval_model = OpenAIModel(model=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
    "qa_correctness_evaluator = QAEvaluator(eval_model)\n",
    "relevance_evaluator = RelevanceEvaluator(eval_model)\n",
    "\n",
    "hallucination_eval_df, qa_correctness_eval_df = run_evals(\n",
    "    dataframe=queries_df,\n",
    "    evaluators=[hallucination_evaluator, qa_correctness_evaluator],\n",
    "    provide_explanation=True,\n",
    ")\n",
    "relevance_eval_df = run_evals(\n",
    "    dataframe=retrieved_documents_df,\n",
    "    evaluators=[relevance_evaluator],\n",
    "    provide_explanation=True,\n",
    ")[0]\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"Hallucination\", dataframe=hallucination_eval_df),\n",
    "    SpanEvaluations(eval_name=\"QA Correctness\", dataframe=qa_correctness_eval_df),\n",
    "    DocumentEvaluations(eval_name=\"Relevance\", dataframe=relevance_eval_df),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seezo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
